<<<<<<< HEAD
#!/usr/bin/env python3
"""
Enhanced OCR Prediction Script
YOLO detection + OCR text extraction + Ground truth validation
"""

import json
import sys
import os
from pathlib import Path
from typing import Optional
from myocr_lib.core import (
    load_model, 
    predict_with_text_extraction, 
    validate_prediction_with_ground_truth,
    batch_validate_with_ground_truth
)

def predict_single_image(image_path: str, confidence: float = 0.25, 
                        validate_with_ground_truth: bool = False):
    """Tek gÃ¶rÃ¼ntÃ¼ iÃ§in enhanced prediction"""
    
    print(f"ðŸ“„ Enhanced OCR Analizi: {image_path}")
    print(f"ðŸŽ¯ Confidence threshold: {confidence}")
    print("=" * 50)
    
    # Model yÃ¼kle
    model = load_model()
    if model is None:
        print("âŒ Model yÃ¼klenemedi!")
        return
    
    if validate_with_ground_truth:
        # Ground truth ile validation
        texts_dir = "enhanced_dataset/texts"
        
        if os.path.exists(texts_dir):
            print("ðŸ” Ground truth ile validation yapÄ±lÄ±yor...")
            
            result = validate_prediction_with_ground_truth(
                model, image_path, texts_dir, confidence
            )
            
            if result['status'] == 'validated':
                print(f"\nðŸ“Š OCR Validation SonuÃ§larÄ±:")
                print(f"   Overall Accuracy: {result['overall_ocr_accuracy']:.3f}")
                print(f"   Validated Fields: {result['validated_fields']}/{result['ground_truth_fields']}")
                
                print(f"\nðŸ” DetaylÄ± KarÅŸÄ±laÅŸtÄ±rma:")
                for validation in result['validation_results']:
                    print(f"   ðŸ“Œ {validation['class_name']}:")
                    print(f"      Predicted: '{validation['predicted_text']}'")
                    print(f"      Ground Truth: '{validation['ground_truth_text']}'")
                    print(f"      Accuracy: {validation['ocr_accuracy']:.3f}")
                    print(f"      Detection Conf: {validation['detection_confidence']:.3f}")
                
            else:
                print("âš ï¸ Bu gÃ¶rÃ¼ntÃ¼ iÃ§in ground truth bulunamadÄ±")
                # Normal prediction yap
                detections = predict_with_text_extraction(model, image_path, confidence)
                display_predictions(detections)
        else:
            print("âš ï¸ Ground truth dizini bulunamadÄ±, normal prediction yapÄ±lÄ±yor")
            detections = predict_with_text_extraction(model, image_path, confidence)
            display_predictions(detections)
    else:
        # Normal prediction
        detections = predict_with_text_extraction(model, image_path, confidence)
        display_predictions(detections)

def display_predictions(detections):
    """Prediction sonuÃ§larÄ±nÄ± gÃ¶ster"""
    if not detections:
        print("âŒ HiÃ§ alan tespit edilmedi!")
        return
    
    print(f"\nðŸŽ¯ Tespit Edilen Alanlar ({len(detections)}):")
    print("-" * 70)
    
    for i, detection in enumerate(detections, 1):
        coords = detection['coordinates']
        print(f"{i:2d}. {detection['class_name']:15s} "
              f"| GÃ¼ven: {detection['confidence']:.3f} "
              f"| Konum: ({coords[0]:.0f},{coords[1]:.0f})-({coords[2]:.0f},{coords[3]:.0f})")
        
        if 'extracted_text' in detection:
            text = detection['extracted_text'][:50] + "..." if len(detection['extracted_text']) > 50 else detection['extracted_text']
            print(f"     ðŸ“ Text: '{text}'")
        print()

def batch_prediction_with_validation(images_dir: str, confidence: float = 0.25, 
                                   max_images: Optional[int] = None):
    """Batch prediction + validation"""
    
    print(f"ðŸ“ Batch Enhanced OCR Analizi: {images_dir}")
    print(f"ðŸŽ¯ Confidence threshold: {confidence}")
    if max_images:
        print(f"ðŸ”¢ Max images: {max_images}")
    print("=" * 70)
    
    # Model yÃ¼kle
    model = load_model()
    if model is None:
        print("âŒ Model yÃ¼klenemedi!")
        return
    
    texts_dir = "enhanced_dataset/texts"
    
    if not os.path.exists(texts_dir):
        print("âš ï¸ Ground truth dizini bulunamadÄ±")
        return
    
    # Batch validation
    print("ðŸ” Batch validation baÅŸlÄ±yor...")
    
    result = batch_validate_with_ground_truth(
        model, images_dir, texts_dir, confidence, max_images
    )
    
    stats = result['statistics']
    
    print(f"\nðŸ“Š Batch Validation SonuÃ§larÄ±:")
    print(f"   Total Images: {stats['total_images']}")
    print(f"   Validated Images: {stats['validated_images']}")
    print(f"   Total Detections: {stats['total_detections']}")
    
    if stats['validated_images'] > 0:
        print(f"   Average OCR Accuracy: {stats['average_accuracy']:.3f}")
        
        print(f"\nðŸ“ˆ Class-wise Accuracies:")
        for class_name, accuracy_data in stats['class_accuracies'].items():
            print(f"   {class_name:15s} | Avg: {accuracy_data['average']:.3f} "
                  f"| Count: {accuracy_data['count']:3d} "
                  f"| Range: {accuracy_data['min']:.3f}-{accuracy_data['max']:.3f}")
    
    # DetaylÄ± sonuÃ§larÄ± kaydet
    output_file = "batch_validation_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    print(f"\nðŸ’¾ DetaylÄ± sonuÃ§lar kaydedildi: {output_file}")

def main():
    """Ana fonksiyon"""
    if len(sys.argv) < 2:
        print("KullanÄ±m:")
        print("  python predict.py <resim_yolu> [confidence] [--validate] [--json-only]")
        print("  python predict.py --batch <images_dir> [confidence] [max_images]")
        print("")
        print("Ã–rnekler:")
        print("  python predict.py fiÅŸ.jpg 0.25                    # Default prediction")
        print("  python predict.py fiÅŸ.jpg 0.25 --validate         # With ground truth validation")
        print("  python predict.py fiÅŸ.jpg 0.25 --json-only        # Only JSON output")
        print("  python predict.py --batch enhanced_dataset/images 0.25 10  # Batch processing")
        return
    
    if sys.argv[1] == "--batch":
        # Batch mode
        if len(sys.argv) < 3:
            print("âŒ Batch mode iÃ§in images dizini gerekli!")
            return
        
        images_dir = sys.argv[2]
        confidence = float(sys.argv[3]) if len(sys.argv) > 3 else 0.25
        max_images = int(sys.argv[4]) if len(sys.argv) > 4 else None
        
        batch_prediction_with_validation(images_dir, confidence, max_images)
        
    else:
        # Single image mode
        image_path = sys.argv[1]
        confidence = float(sys.argv[2]) if len(sys.argv) > 2 else 0.25
        validate = "--validate" in sys.argv
        
        predict_single_image(image_path, confidence, validate)

if __name__ == "__main__":
    main() 
=======
import cv2
import argparse
from ultralytics import YOLO
import json

from myocr_lib import id_to_class, extract_text_from_box

def predict_and_extract(image_path, model_path='runs/detect/train/weights/best.pt'):
    """
    Verilen gÃ¶rÃ¼ntÃ¼ Ã¼zerinde YOLO ile alan tespiti yapar ve
    her alan iÃ§in OCR ile metin Ã§Ä±karÄ±mÄ± yapar.
    """
    # Modeli yÃ¼kle
    try:
        model = YOLO(model_path)
    except Exception as e:
        print(f"Hata: Model yÃ¼klenemedi. Model yolu doÄŸru mu?: {model_path}")
        print(f"Detay: {e}")
        return
        
    # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
    try:
        image = cv2.imread(image_path)
        if image is None:
            raise FileNotFoundError(f"GÃ¶rÃ¼ntÃ¼ dosyasÄ± bulunamadÄ± veya okunamadÄ±: {image_path}")
    except Exception as e:
        print(e)
        return

    # YOLO ile tahmin yap
    results = model(image_path, verbose=False)
    
    # Tespit edilen her bir kutu iÃ§in iÅŸlem yap
    detections = []
    if results and results[0].boxes is not None:
        for box in results[0].boxes:
            # SÄ±nÄ±f ID'sini al
            class_id = int(box.cls[0])
            # SÄ±nÄ±f adÄ±nÄ± al
            class_name = id_to_class.get(class_id, "bilinmeyen_sinif")
            
            # KoordinatlarÄ± al
            coords = box.xyxy[0].tolist()
            
            # GÃ¼ven skorunu al
            confidence = float(box.conf[0])
            
            detections.append({
                "class_name": class_name,
                "class_id": class_id,
                "coordinates": coords,
                "confidence": confidence
            })

    # Tespit edilen alanlardan metinleri Ã§Ä±kar
    extracted_data = {}
    
    # Orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ OCR iÃ§in kullan
    original_image_for_ocr = cv2.imread(image_path)
    
    for detection in detections:
        text = extract_text_from_box(original_image_for_ocr, detection['coordinates'])
        
        # AynÄ± sÄ±nÄ±ftan birden fazla tespit varsa listeye ekle
        if detection['class_name'] in extracted_data:
            # EÄŸer mevcut deÄŸer bir liste deÄŸilse, listeye Ã§evir
            if not isinstance(extracted_data[detection['class_name']], list):
                extracted_data[detection['class_name']] = [extracted_data[detection['class_name']]]
            extracted_data[detection['class_name']].append(text)
        else:
            extracted_data[detection['class_name']] = text


    # SonuÃ§larÄ± JSON formatÄ±nda birleÅŸtir
    final_result = {
        "image_path": image_path,
        "detections_count": len(detections),
        "extracted_text": extracted_data,
        "raw_detections": detections,
    }

    return final_result

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="YOLO ve OCR ile fiÅŸ bilgilerini Ã§Ä±karma")
    parser.add_argument("image_path", help="Ä°ÅŸlenecek fiÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼n yolu")
    parser.add_argument("--model", default="runs/detect/train/weights/best.pt", help="EÄŸitilmiÅŸ YOLO modelinin yolu")
    args = parser.parse_args()

    # Ä°ÅŸlemi baÅŸlat
    results_json = predict_and_extract(args.image_path, args.model)
    
    # SonuÃ§larÄ± dÃ¼zgÃ¼n formatlÄ± JSON olarak yazdÄ±r
    if results_json:
        print(json.dumps(results_json, indent=4, ensure_ascii=False)) 
>>>>>>> main
